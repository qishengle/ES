进程和线程

Unix/Linux操作系统提供了一个fork()【-当前进程（称为父进程）复制了一份（称为子进程）-】，
调用一次，返回两次
子进程永远返回0，而父进程返回子进程的ID。
子进程只需要调用getppid()就可以拿到父进程的ID

如果要启动大量的子进程，可以用进程池的方式批量创建子进程
multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。

父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在
Windows下调用失败了，要先考虑是不是pickle失败了。


小结：
在Unix/Linux下，可以使用fork()调用实现多进程。
要实现跨平台的多进程，可以使用multiprocessing块。
进程间通信是通过Queue、Pipes等实现的。

--------------------------------------------------------------------------------------------------
Python的线程是真正的Posix Thread，而不是模拟出来的线程。
多任务可以由多进程完成，也可以由一个进程内的多线程完成。
启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行

Python的标准库提供了两个模块：_thread 低级模块，threading 高级模块(对_thread进行了封装)。

任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程
threading模块有个current_thread()函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，
子线程的名字在创建时指定

多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响; 而多线程中，所有变量都由所有线程共享.
线程之间共享数据最大的危险在于多个线程同时改一个变量,因此线程中引入了--锁，通过threading.Lock()实现

用try...finally来确保锁一定会被释放，是个好的编程习惯
锁能保证代码的完整性，但有死锁问题风险。由于阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程
模式执行，效率就大大地下降了。
-----------------------------------------------------
Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，
任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，
让别的线程有机会执行。即使100个线程跑在100核CPU上，也只能用到1个核
-----------------------------------------------------
多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。

Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。


ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等
ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。
ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题


多进程模式最大的优点就是稳定性高,缺点是创建进程的代价大.
切换作业是有代价的,如 保存现场

任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，
计算密集型任务同时进行的数量应当等于CPU的核心数。
计算密集型任务由于主要消耗CPU资源，Python这样的脚本语言完全不适合，最好用C语言。

IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分
时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。脚本语言是首选

异步IO，可单进程单线程模型来执行基于IO的多任务，又称事件驱动模型，Nginx就是支持异步IO的Web服务器

-----------------------------------------------------------------
分布式进程

Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。
服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务(master.py);
然后，在其他机器上启动任务进程（本机上启动也可以）(worker.py)

Queue之所以能通过网络访问，就是通过QueueManager实现的。由于QueueManager管理的不止一个Queue，
所以，要给每个Queue的网络调用接口起个名字，比如get_task_queue。

Master/Worker模型就是一个简单但真正的分布式计算

********************************************

正则
Python提供re模块，包含所有正则表达式的功能。正则字符串使用Python的r前缀，就不用考虑转义的问题了

内建模块

》》from datetime import datetime
对日期和时间进行加减，可以直接用+和-运算符，不过需要导入timedelta这个类
如果要存储datetime，最佳方法是将其转换为timestamp再存储，因为timestamp的值与时区完全无关。

》》from collections import namedtuple
namedtuple是一个函数，它用来创建一个自定义的tuple对象，并且规定了tuple元素的个数，并可以用属性
而不是索引来引用tuple的某个元素。
如：类似的，如果要用坐标和半径表示一个圆，也可以用namedtuple定义：
# namedtuple('名称', [属性list]):
Circle = namedtuple('Circle', ['x', 'y', 'r'])

>>> from collections import deque
使用list存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了，因为list是线性存储，
数据量大的时候，插入和删除效率很低

deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈
deque除了实现list的append()和pop()外，还支持appendleft()和popleft()，往头部添加或删除元素

》》from collections import OrderedDict
OrderedDict可以实现一个FIFO（先进先出）的dict，当容量超出限制时，先删除最早添加的Key


Python提供了一个struct模块来解决bytes和其他二进制数据类型的转换。
struct的pack函数把任意数据类型变成bytes; unpack把bytes变成相应的数据类型

Python的hashlib提供了常见的摘要算法，如MD5，SHA1等。

itertools模块提供的全部是处理迭代功能的函数，它们的返回值不是list，而是Iterator，只有用for循环
迭代的时候才真正计算。


操作XML有两种方法：DOM和SAX。DOM会把整个XML读入内存，解析为树，因此占用内存大，解析慢，优点是可以
任意遍历树的节点。SAX是流模式，边读边解析，占用内存小，解析快，缺点是我们需要自己处理事件。
正常情况下，优先考虑SAX，因为DOM实在太占内存。

Python提供了HTMLParser,非常方便地把网页HTML中的文本、图像等解析出来

urllib提供了一系列用于操作URL的功能。
urllib的request模块可以抓取URL内容，即发送一个GET请求到指定的页面，然后返回HTTP的响应
模拟浏览器发送GET请求，需要使用Request对象。Request对象添加HTTP头，我们就可以把请求伪装成浏览器

所有的第三方模块都会在PyPI - the Python Package Index上注册，只要找到对应的模块名字，即可用pip安装。


************************

Python支持多种图形界面的第三方库，包括：

    Tk

    wxWidgets

    Qt

    GTK

**********************************
网络编程


****************************************

SMTP是发送邮件的协议，Python内置对SMTP的支持，可以发送纯文本邮件、HTML邮件以及带附件的邮件。
Python对SMTP支持有smtplib和email两个模块，email负责构造邮件，smtplib负责发送邮件

收取邮件就是编写一个MUA作为客户端，从MDA把邮件获取到用户的电脑或者手机上。收取邮件最常用的协议是POP
协议，目前版本号是3，俗称POP3。

Python内置一个poplib模块，实现了POP3协议，可以直接用来收邮件。
把POP3收取的文本变成可阅读的邮件，还需email模块提供的各种类来解析原始文本，变成可阅读的邮件对象。

所以，收取邮件分两步：
第一步：用poplib把邮件的原始文本下载到本地；
第二部：用email解析原始文本，还原为邮件对象

******************************************
在Python中操作数据库时，要先导入数据库对应的驱动，然后，通过Connection对象和Cursor对象操作数据。

要确保打开的Connection对象和Cursor对象都正确地被关闭，否则，资源就会泄露。

如何才能确保出错的情况下也关闭掉Connection对象和Cursor对象呢？请回忆try:...except:...finally:...的用法。

**********************************************
centos7安装mariadb包含MySQL，然后下载驱动
pip/pip3 install pymysql
mysql.connector都改成pymysql

ORM框架的作用就是把数据库表的一行记录与一个对象互相做自动转换。

*************************************************
HTTP请求

跟踪了新浪的首页，我们来总结一下HTTP请求的流程：

步骤1：浏览器首先向服务器发送HTTP请求，请求包括：

方法：GET还是POST，GET仅请求资源，POST会附带用户数据；
路径：/full/url/path；
域名：由Host头指定：Host: www.sina.com.cn
以及其他相关的Header；
如果是POST，那么请求还包括一个Body，包含用户数据。

步骤2：服务器向浏览器返回HTTP响应，响应包括：

响应代码：200表示成功，3xx表示重定向，4xx表示客户端发送的请求有错误，5xx表示服务器端处理时发生了错误；
响应类型：由Content-Type指定；
以及其他相关的Header；
通常服务器的HTTP响应会携带内容，也就是有一个Body，包含响应的内容，网页的HTML源码就在Body中。

步骤3：如果浏览器还需要继续向服务器请求其他资源，比如图片，就再次发出HTTP请求，重复步骤1、2。


HTTP/1.1指示采用的HTTP协议版本是1.1。
目前HTTP协议的版本就是1.1，但是大部分服务器也支持1.0版本，主要区别在于1.1版本允许多个HTTP请求
复用一个TCP连接，以加快传输速度。

----------------------------------------------------------
Web应用的本质就是：

    浏览器发送一个HTTP请求；

    服务器收到请求，生成一个HTML文档；

    服务器把HTML文档作为HTTP响应的Body发送给浏览器；

    浏览器收到HTTP响应，从HTTP Body取出HTML文档并显示

**********************************************

在“发出IO请求”到收到“IO完成”的这段时间里，同步IO模型下，主线程只能挂起
但异步IO模型下，主线程并没有休息，而是在消息循环中继续处理其他消息。当IO操作完成后，主线程
将收到一条“IO完成”的消息，处理该消息时就可以直接获取IO操作结果。

************************************

协程的特点在于是一个线程执行。
最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，
没有线程切换的开销
第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突

asyncio提供了完善的异步IO支持；

异步操作需要在coroutine中通过yield from完成；

多个coroutine可以封装成一组Task然后并发执行。

异步编程的一个原则：一旦决定使用异步，则系统每一层都必须是异步，“开弓没有回头箭”。



